{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOo22VyQNuNY",
        "outputId": "08c16610-8b75-432b-f5f0-3938a6bdca7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 80)                3520      \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 30)                2430      \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 1)                 31        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5981 (23.36 KB)\n",
            "Trainable params: 5981 (23.36 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "804/804 [==============================] - 9s 8ms/step - loss: 0.5708 - accuracy: 0.7231\n",
            "Epoch 2/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5556 - accuracy: 0.7293\n",
            "Epoch 3/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5528 - accuracy: 0.7304\n",
            "Epoch 4/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5510 - accuracy: 0.7306\n",
            "Epoch 5/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5500 - accuracy: 0.7303\n",
            "Epoch 6/100\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5486 - accuracy: 0.7328\n",
            "Epoch 7/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5479 - accuracy: 0.7324\n",
            "Epoch 8/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5470 - accuracy: 0.7336\n",
            "Epoch 9/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5467 - accuracy: 0.7334\n",
            "Epoch 10/100\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5464 - accuracy: 0.7332\n",
            "Epoch 11/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5455 - accuracy: 0.7336\n",
            "Epoch 12/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5454 - accuracy: 0.7341\n",
            "Epoch 13/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5450 - accuracy: 0.7345\n",
            "Epoch 14/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5438 - accuracy: 0.7346\n",
            "Epoch 15/100\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5440 - accuracy: 0.7328\n",
            "Epoch 16/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5433 - accuracy: 0.7348\n",
            "Epoch 17/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5427 - accuracy: 0.7347\n",
            "Epoch 18/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5432 - accuracy: 0.7349\n",
            "Epoch 19/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5426 - accuracy: 0.7343\n",
            "Epoch 20/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5427 - accuracy: 0.7349\n",
            "Epoch 21/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5425 - accuracy: 0.7358\n",
            "Epoch 22/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5423 - accuracy: 0.7362\n",
            "Epoch 23/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5415 - accuracy: 0.7356\n",
            "Epoch 24/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5410 - accuracy: 0.7359\n",
            "Epoch 25/100\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5408 - accuracy: 0.7364\n",
            "Epoch 26/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5414 - accuracy: 0.7355\n",
            "Epoch 27/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5408 - accuracy: 0.7362\n",
            "Epoch 28/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5405 - accuracy: 0.7363\n",
            "Epoch 29/100\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5404 - accuracy: 0.7363\n",
            "Epoch 30/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5405 - accuracy: 0.7367\n",
            "Epoch 31/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5402 - accuracy: 0.7362\n",
            "Epoch 32/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5399 - accuracy: 0.7372\n",
            "Epoch 33/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5401 - accuracy: 0.7355\n",
            "Epoch 34/100\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.5400 - accuracy: 0.7367\n",
            "Epoch 35/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5395 - accuracy: 0.7374\n",
            "Epoch 36/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5393 - accuracy: 0.7372\n",
            "Epoch 37/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5392 - accuracy: 0.7369\n",
            "Epoch 38/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5391 - accuracy: 0.7370\n",
            "Epoch 39/100\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5396 - accuracy: 0.7370\n",
            "Epoch 40/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5392 - accuracy: 0.7372\n",
            "Epoch 41/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5393 - accuracy: 0.7372\n",
            "Epoch 42/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5387 - accuracy: 0.7372\n",
            "Epoch 43/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5387 - accuracy: 0.7378\n",
            "Epoch 44/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5383 - accuracy: 0.7371\n",
            "Epoch 45/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5386 - accuracy: 0.7370\n",
            "Epoch 46/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5383 - accuracy: 0.7381\n",
            "Epoch 47/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5382 - accuracy: 0.7382\n",
            "Epoch 48/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5381 - accuracy: 0.7381\n",
            "Epoch 49/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5377 - accuracy: 0.7374\n",
            "Epoch 50/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5377 - accuracy: 0.7380\n",
            "Epoch 51/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5381 - accuracy: 0.7380\n",
            "Epoch 52/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5377 - accuracy: 0.7383\n",
            "Epoch 53/100\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5372 - accuracy: 0.7385\n",
            "Epoch 54/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5376 - accuracy: 0.7375\n",
            "Epoch 55/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5376 - accuracy: 0.7385\n",
            "Epoch 56/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5375 - accuracy: 0.7383\n",
            "Epoch 57/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5370 - accuracy: 0.7392\n",
            "Epoch 58/100\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5372 - accuracy: 0.7382\n",
            "Epoch 59/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5374 - accuracy: 0.7392\n",
            "Epoch 60/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5367 - accuracy: 0.7388\n",
            "Epoch 61/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5370 - accuracy: 0.7384\n",
            "Epoch 62/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5371 - accuracy: 0.7386\n",
            "Epoch 63/100\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5369 - accuracy: 0.7393\n",
            "Epoch 64/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5372 - accuracy: 0.7381\n",
            "Epoch 65/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5365 - accuracy: 0.7374\n",
            "Epoch 66/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5373 - accuracy: 0.7381\n",
            "Epoch 67/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5367 - accuracy: 0.7388\n",
            "Epoch 68/100\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5364 - accuracy: 0.7389\n",
            "Epoch 69/100\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5364 - accuracy: 0.7382\n",
            "Epoch 70/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5361 - accuracy: 0.7386\n",
            "Epoch 71/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5365 - accuracy: 0.7391\n",
            "Epoch 72/100\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5361 - accuracy: 0.7401\n",
            "Epoch 73/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5363 - accuracy: 0.7389\n",
            "Epoch 74/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5360 - accuracy: 0.7393\n",
            "Epoch 75/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5359 - accuracy: 0.7387\n",
            "Epoch 76/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5362 - accuracy: 0.7369\n",
            "Epoch 77/100\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5359 - accuracy: 0.7395\n",
            "Epoch 78/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5358 - accuracy: 0.7390\n",
            "Epoch 79/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5359 - accuracy: 0.7394\n",
            "Epoch 80/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5357 - accuracy: 0.7399\n",
            "Epoch 81/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5361 - accuracy: 0.7381\n",
            "Epoch 82/100\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5357 - accuracy: 0.7396\n",
            "Epoch 83/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5359 - accuracy: 0.7395\n",
            "Epoch 84/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5355 - accuracy: 0.7393\n",
            "Epoch 85/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5358 - accuracy: 0.7395\n",
            "Epoch 86/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5356 - accuracy: 0.7398\n",
            "Epoch 87/100\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5356 - accuracy: 0.7397\n",
            "Epoch 88/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5354 - accuracy: 0.7391\n",
            "Epoch 89/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5356 - accuracy: 0.7388\n",
            "Epoch 90/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5353 - accuracy: 0.7402\n",
            "Epoch 91/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5351 - accuracy: 0.7399\n",
            "Epoch 92/100\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5348 - accuracy: 0.7397\n",
            "Epoch 93/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5355 - accuracy: 0.7391\n",
            "Epoch 94/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5351 - accuracy: 0.7397\n",
            "Epoch 95/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5351 - accuracy: 0.7399\n",
            "Epoch 96/100\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5351 - accuracy: 0.7390\n",
            "Epoch 97/100\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5349 - accuracy: 0.7397\n",
            "Epoch 98/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5349 - accuracy: 0.7400\n",
            "Epoch 99/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5349 - accuracy: 0.7404\n",
            "Epoch 100/100\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5350 - accuracy: 0.7395\n",
            "268/268 - 1s - loss: 0.5651 - accuracy: 0.7290 - 551ms/epoch - 2ms/step\n",
            "Loss: 0.5651176571846008, Accuracy: 0.7289795875549316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# %% [markdown]\n",
        "# ## Preprocessing\n",
        "\n",
        "# %%\n",
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "#  Import and read the charity_data.csv.\n",
        "import pandas as pd\n",
        "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
        "application_df.head()\n",
        "\n",
        "# %%\n",
        "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
        "application_df = application_df.drop(columns=['EIN', 'NAME'])\n",
        "\n",
        "# %%\n",
        "# Determine the number of unique values in each column.\n",
        "application_df.nunique()\n",
        "\n",
        "# %%\n",
        "# Look at APPLICATION_TYPE value counts to identify and replace with \"Other\"\n",
        "application_df['APPLICATION_TYPE'].value_counts()\n",
        "\n",
        "# %%\n",
        "# Choose a cutoff value and create a list of application types to be replaced\n",
        "# use the variable name `application_types_to_replace`\n",
        "application_types_to_replace =application_df['APPLICATION_TYPE'].value_counts()[application_df['APPLICATION_TYPE'].value_counts()<500].index\n",
        "\n",
        "# Replace in dataframe\n",
        "for app in application_types_to_replace:\n",
        "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
        "\n",
        "# Check to make sure replacement was successful\n",
        "application_df['APPLICATION_TYPE'].value_counts()\n",
        "\n",
        "\n",
        "# %%\n",
        "# Look at CLASSIFICATION value counts to identify and replace with \"Other\"\n",
        "application_df['CLASSIFICATION'].value_counts\n",
        "\n",
        "# %%\n",
        "# You may find it helpful to look at CLASSIFICATION value counts >1\n",
        "classification_value_counts = application_df[\"CLASSIFICATION\"].value_counts()\n",
        "classification_value_counts[classification_value_counts > 1]\n",
        "\n",
        "# %%\n",
        "# Choose a cutoff value and create a list of classifications to be replaced\n",
        "# use the variable name `classifications_to_replace`\n",
        "classifications_to_replace = classification_value_counts[classification_value_counts < 1000].index\n",
        "\n",
        "# Replace in dataframe\n",
        "for cls in classifications_to_replace:\n",
        "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
        "\n",
        "# Check to make sure replacement was successful\n",
        "application_df['CLASSIFICATION'].value_counts()\n",
        "\n",
        "# %%\n",
        "# Convert categorical data to numeric with `pd.get_dummies`\n",
        "application_type_dummies  = pd.get_dummies(application_df['APPLICATION_TYPE'], dtype='int')\n",
        "classification_dummies = pd.get_dummies(application_df['CLASSIFICATION'], dtype='int')\n",
        "affiliation_dummies = pd.get_dummies(application_df['AFFILIATION'], dtype='int')\n",
        "usecase_dummies  = pd.get_dummies(application_df['USE_CASE'], dtype='int')\n",
        "organization_dummies = pd.get_dummies(application_df['ORGANIZATION'], dtype='int')\n",
        "income_dummies = pd.get_dummies(application_df['INCOME_AMT'], dtype='int')\n",
        "type_dummies = pd.get_dummies(application_df['SPECIAL_CONSIDERATIONS'], dtype='int')\n",
        "\n",
        "# Concatenate the 'application type' and 'classification' dummies with the application_df\n",
        "application_df = pd.concat([application_df, application_type_dummies, classification_dummies, affiliation_dummies, usecase_dummies, organization_dummies,income_dummies, type_dummies],axis=1)\n",
        "\n",
        "# Drop the original 'APPLICATION_TYPE' and 'CLASSIFICATION' columns from the application_df\n",
        "application_df = application_df.drop(columns=['APPLICATION_TYPE', 'CLASSIFICATION','AFFILIATION','USE_CASE','ORGANIZATION','INCOME_AMT','SPECIAL_CONSIDERATIONS'])\n",
        "\n",
        "# %%\n",
        "# Split our preprocessed data into our features and target arrays\n",
        "x = application_df.drop(columns=[\"IS_SUCCESSFUL\"])\n",
        "y = application_df[\"IS_SUCCESSFUL\"]\n",
        "\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "x_train, X_test, y_train, y_test = train_test_split(x, y, random_state=1, stratify=y)\n",
        "\n",
        "# %%\n",
        "# Create a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "x_scaler = scaler.fit(x_train)\n",
        "\n",
        "# Scale the data\n",
        "x_train_scaled = x_scaler.transform(x_train)\n",
        "x_test_scaled = x_scaler.transform(X_test)\n",
        "\n",
        "# %% [markdown]\n",
        "# ## Compile, Train and Evaluate the Model\n",
        "\n",
        "# %%\n",
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "input_dim = 100\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer,\n",
        "nn.add(tf.keras.layers.Dense(units =80 , activation=\"relu\", input_dim=43))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=30, activation=\"relu\"))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()\n",
        "\n",
        "# %%\n",
        "# Compile the model\n",
        "nn.compile(optimizer='adam',\n",
        "           loss='binary_crossentropy',\n",
        "           metrics=['accuracy'])\n",
        "\n",
        "# %%\n",
        "# Train the model\n",
        "nn.fit(x_train_scaled, y_train, epochs = 100)\n",
        "\n",
        "# %%\n",
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(x_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
        "\n",
        "# %%\n",
        "# Export our model to HDF5 file\n",
        "nn.save(\"ApphabetSoupCharity.h5\")\n",
        "\n",
        "\n"
      ]
    }
  ]
}